{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17792f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-19 22:36:42.644790: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-19 22:36:42.650843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752957402.657743  216241 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752957402.660059  216241 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752957402.665975  216241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752957402.665984  216241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752957402.665985  216241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752957402.665986  216241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-19 22:36:42.667986: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from extraction.keywordsExtraction import KeywordsExtractor\n",
    "from apiIntegration.arxiveAPI import ArxivAPI\n",
    "from embedding.embeddingArticle import EmbeddingArticle\n",
    "from pdfToText.pdfToText import PDFToText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816876f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Jak w badaniu czarnych dziur oraz przestrzeni kosmicznej pomaga sztuczna inteligencja?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b6f237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = KeywordsExtractor(text=text).get_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca45fdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords: ('intelligence', 'study', 'holes', 'space', 'artificial')\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracted Keywords:\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d59c35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the keyword strings from the tuples\n",
    "download_articles = ArxivAPI(keyword_list=keywords, max_results=20, download_directory='archive').search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc87b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded articles: [{'title': 'On the Latent Holes of VAEs for Text Generation', 'summary': \"In this paper, we provide the first focused study on the discontinuities\\n(aka. holes) in the latent space of Variational Auto-Encoders (VAEs), a\\nphenomenon which has been shown to have a detrimental effect on model capacity.\\nWhen investigating latent holes, existing works are exclusively centred around\\nthe encoder network and they merely explore the existence of holes. We tackle\\nthese limitations by proposing a highly efficient Tree-based Decoder-Centric\\n(TDC) algorithm for latent hole identification, with a focal point on the text\\ndomain. In contrast to past studies, our approach pays attention to the decoder\\nnetwork, as a decoder has a direct impact on the model's output quality.\\nFurthermore, we provide, for the first time, in-depth empirical analysis of the\\nlatent hole phenomenon, investigating several important aspects such as how the\\nholes impact VAE algorithms' performance on text generation, and how the holes\\nare distributed in the latent space.\", 'authors': ['Ruizhe Li', 'Xutan Peng', 'Chenghua Lin'], 'published': datetime.datetime(2021, 10, 7, 10, 22, 4, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2110.03318v1'}, {'title': 'Analysis and Predictive Modeling of Solar Coronal Holes Using Computer Vision and ARIMA-LSTM Networks', 'summary': 'In the era of space exploration, coronal holes on the sun play a significant\\nrole due to their impact on satellites and aircraft through their open magnetic\\nfields and increased solar wind emissions. This study employs computer vision\\ntechniques to detect coronal hole regions and estimate their sizes using\\nimagery from the Solar Dynamics Observatory (SDO). Additionally, we utilize\\nhybrid time series prediction model, specifically combination of Long\\nShort-Term Memory (LSTM) networks and ARIMA, to analyze trends in the area of\\ncoronal holes and predict their areas across various solar regions over a span\\nof seven days. By examining time series data, we aim to identify patterns in\\ncoronal hole behavior and understand their potential effects on space weather.', 'authors': ['Juyoung Yun', 'Jungmin Shin'], 'published': datetime.datetime(2024, 5, 16, 4, 21, 9, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2405.09802v3'}, {'title': 'Artificial Intelligence Technology analysis using Artificial Intelligence patent through Deep Learning model and vector space model', 'summary': \"Thanks to rapid development of artificial intelligence technology in recent\\nyears, the current artificial intelligence technology is contributing to many\\npart of society. Education, environment, medical care, military, tourism,\\neconomy, politics, etc. are having a very large impact on society as a whole.\\nFor example, in the field of education, there is an artificial intelligence\\ntutoring system that automatically assigns tutors based on student's level. In\\nthe field of economics, there are quantitative investment methods that\\nautomatically analyze large amounts of data to find investment laws to create\\ninvestment models or predict changes in financial markets. As such, artificial\\nintelligence technology is being used in various fields. So, it is very\\nimportant to know exactly what factors have an important influence on each\\nfield of artificial intelligence technology and how the relationship between\\neach field is connected. Therefore, it is necessary to analyze artificial\\nintelligence technology in each field. In this paper, we analyze patent\\ndocuments related to artificial intelligence technology. We propose a method\\nfor keyword analysis within factors using artificial intelligence patent data\\nsets for artificial intelligence technology analysis. This is a model that\\nrelies on feature engineering based on deep learning model named KeyBERT, and\\nusing vector space model. A case study of collecting and analyzing artificial\\nintelligence patent data was conducted to show how the proposed model can be\\napplied to real world problems.\", 'authors': ['Yongmin Yoo', 'Dongjin Lim', 'Kyungsun Kim'], 'published': datetime.datetime(2021, 11, 8, 0, 10, 49, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2111.11295v1'}, {'title': 'Artificial black holes', 'summary': \"We study black holes for the linear hyperbolic equations describing the wave\\npropagation in the moving medium. Such black holes are called artificial since\\nthe Lorentz metric associated with the hyperbolic equation does not necessary\\nsatisfies the Einstein equations. Artificial black holes also arise when we\\nconsider perturbations of the Einstein equations. In this paper we review\\nauthor's results of [E2] and [E3] on the existence and the stability of black\\nholes for the stationary wave equations in two space dimensions, and in the\\naxisymmetric case.\", 'authors': ['Gregory Eskin'], 'published': datetime.datetime(2011, 5, 10, 18, 44, 22, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/1105.2015v1'}, {'title': 'Leveraging Procedural Generation for Learning Autonomous Peg-in-Hole Assembly in Space', 'summary': 'The ability to autonomously assemble structures is crucial for the\\ndevelopment of future space infrastructure. However, the unpredictable\\nconditions of space pose significant challenges for robotic systems,\\nnecessitating the development of advanced learning techniques to enable\\nautonomous assembly. In this study, we present a novel approach for learning\\nautonomous peg-in-hole assembly in the context of space robotics. Our focus is\\non enhancing the generalization and adaptability of autonomous systems through\\ndeep reinforcement learning. By integrating procedural generation and domain\\nrandomization, we train agents in a highly parallelized simulation environment\\nacross a spectrum of diverse scenarios with the aim of acquiring a robust\\npolicy. The proposed approach is evaluated using three distinct reinforcement\\nlearning algorithms to investigate the trade-offs among various paradigms. We\\ndemonstrate the adaptability of our agents to novel scenarios and assembly\\nsequences while emphasizing the potential of leveraging advanced simulation\\ntechniques for robot learning in space. Our findings set the stage for future\\nadvancements in intelligent robotic systems capable of supporting ambitious\\nspace missions and infrastructure development beyond Earth.', 'authors': ['Andrej Orsula', 'Matthieu Geist', 'Miguel Olivares-Mendez', 'Carol Martinez'], 'published': datetime.datetime(2024, 5, 2, 9, 50, 1, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2405.01134v1'}, {'title': 'Symmetry-aware Reinforcement Learning for Robotic Assembly under Partial Observability with a Soft Wrist', 'summary': 'This study tackles the representative yet challenging contact-rich\\npeg-in-hole task of robotic assembly, using a soft wrist that can operate more\\nsafely and tolerate lower-frequency control signals than a rigid one. Previous\\nstudies often use a fully observable formulation, requiring external setups or\\nestimators for the peg-to-hole pose. In contrast, we use a partially observable\\nformulation and deep reinforcement learning from demonstrations to learn a\\nmemory-based agent that acts purely on haptic and proprioceptive signals.\\nMoreover, previous works do not incorporate potential domain symmetry and thus\\nmust search for solutions in a bigger space. Instead, we propose to leverage\\nthe symmetry for sample efficiency by augmenting the training data and\\nconstructing auxiliary losses to force the agent to adhere to the symmetry.\\nResults in simulation with five different symmetric peg shapes show that our\\nproposed agent can be comparable to or even outperform a state-based agent. In\\nparticular, the sample efficiency also allows us to learn directly on the real\\nrobot within 3 hours.', 'authors': ['Hai Nguyen', 'Tadashi Kozuno', 'Cristian C. Beltran-Hernandez', 'Masashi Hamaya'], 'published': datetime.datetime(2024, 2, 28, 2, 30, 59, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2402.18002v2'}, {'title': 'Does an artificial intelligence perform market manipulation with its own discretion? -- A genetic algorithm learns in an artificial market simulation', 'summary': 'Who should be charged with responsibility for an artificial intelligence\\nperforming market manipulation have been discussed. In this study, I\\nconstructed an artificial intelligence using a genetic algorithm that learns in\\nan artificial market simulation, and investigated whether the artificial\\nintelligence discovers market manipulation through learning with an artificial\\nmarket simulation despite a builder of artificial intelligence has no intention\\nof market manipulation. As a result, the artificial intelligence discovered\\nmarket manipulation as an optimal investment strategy. This result suggests\\nnecessity of regulation, such as obligating builders of artificial intelligence\\nto prevent artificial intelligence from performing market manipulation.', 'authors': ['Takanobu Mizuta'], 'published': datetime.datetime(2020, 5, 21, 7, 0, 31, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2005.10488v1'}, {'title': 'In Search of Extraterrestrial Artificial Intelligence Through Dyson Sphere-like structures around Primordial Black Holes', 'summary': 'Are we alone? It is a compelling question that human beings have confronted\\nfor centuries. The search for extraterrestrial life is a broad range of quests\\nfor finding simple forms of life up to intelligent beings in the Universe. The\\nplausible assumption is that there is a chance that intelligent life will be\\nfollowed by advanced civilization equipped or even dominated by artificial\\nintelligence (AI). In this work, we categorize advanced civilizations (on an\\nequal footing, an AI-dominated civilization) on the Kardashev scale. We propose\\na new scale known as the space exploration distance to measure civilization\\nadvancement. We propose a relation between this length and the Kardashev scale.\\nThen, we suggest the idea that advanced civilizations will use primordial black\\nholes (PBHs) as sources of harvesting energy. We calculate the energy harvested\\nby calculating the space exploration distance. Finally, we propose an\\nobservational method to detect the possibility of extraterrestrial AI using\\nDyson sphere-like structures around PBHs in the Milky Way and other galaxies.', 'authors': ['Shant Baghram'], 'published': datetime.datetime(2024, 12, 3, 18, 45, 18, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2412.02671v2'}, {'title': 'The Riddle of Togelby', 'summary': 'At the 2017 Artificial and Computational Intelligence in Games meeting at\\nDagstuhl, Julian Togelius asked how to make spaces where every way of filling\\nin the details yielded a good game. This study examines the possibility of\\nenriching search spaces so that they contain very high rates of interesting\\nobjects, specifically game elements. While we do not answer the full challenge\\nof finding good games throughout the space, this study highlights a number of\\npotential avenues. These include naturally rich spaces, a simple technique for\\nmodifying a representation to search only rich parts of a larger search space,\\nand representations that are highly expressive and so exhibit highly restricted\\nand consequently enriched search spaces.', 'authors': ['Daniel Ashlock', 'Christoph Salge'], 'published': datetime.datetime(2019, 6, 10, 14, 16, 2, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/1906.03997v1'}, {'title': 'Impact of Artificial Intelligence on Economic Theory', 'summary': 'Artificial intelligence has impacted many aspects of human life. This paper\\nstudies the impact of artificial intelligence on economic theory. In particular\\nwe study the impact of artificial intelligence on the theory of bounded\\nrationality, efficient market hypothesis and prospect theory.', 'authors': ['Tshilidzi Marwala'], 'published': datetime.datetime(2015, 7, 1, 16, 26, 21, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/1509.01213v1'}, {'title': 'Integrated Drill Boom Hole-Seeking Control via Reinforcement Learning', 'summary': 'Intelligent drill boom hole-seeking is a promising technology for enhancing\\ndrilling efficiency, mitigating potential safety hazards, and relieving human\\noperators. Most existing intelligent drill boom control methods rely on a\\nhierarchical control framework based on inverse kinematics. However, these\\nmethods are generally time-consuming due to the computational complexity of\\ninverse kinematics and the inefficiency of the sequential execution of multiple\\njoints. To tackle these challenges, this study proposes an integrated drill\\nboom control method based on Reinforcement Learning (RL). We develop an\\nintegrated drill boom control framework that utilizes a parameterized policy to\\ndirectly generate control inputs for all joints at each time step, taking\\nadvantage of joint posture and target hole information. By formulating the\\nhole-seeking task as a Markov decision process, contemporary mainstream RL\\nalgorithms can be directly employed to learn a hole-seeking policy, thus\\neliminating the need for inverse kinematics solutions and promoting cooperative\\nmulti-joint control. To enhance the drilling accuracy throughout the entire\\ndrilling process, we devise a state representation that combines\\nDenavit-Hartenberg joint information and preview hole-seeking discrepancy data.\\nSimulation results show that the proposed method significantly outperforms\\ntraditional methods in terms of hole-seeking accuracy and time efficiency.', 'authors': ['Haoqi Yan', 'Haoyuan Xu', 'Hongbo Gao', 'Fei Ma', 'Shengbo Eben Li', 'Jingliang Duan'], 'published': datetime.datetime(2023, 12, 4, 12, 16, 2, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2312.01836v1'}, {'title': 'AI-as-exploration: Navigating intelligence space', 'summary': \"Artificial Intelligence is a field that lives many lives, and the term has\\ncome to encompass a motley collection of scientific and commercial endeavours.\\nIn this paper, I articulate the contours of a rather neglected but central\\nscientific role that AI has to play, which I dub `AI-as-exploration'.The basic\\nthrust of AI-as-exploration is that of creating and studying systems that can\\nreveal candidate building blocks of intelligence that may differ from the forms\\nof human and animal intelligence we are familiar with. In other words, I\\nsuggest that AI is one of the best tools we have for exploring intelligence\\nspace, namely the space of possible intelligent systems. I illustrate the value\\nof AI-as-exploration by focusing on a specific case study, i.e., recent work on\\nthe capacity to combine novel and invented concepts in humans and Large\\nLanguage Models. I show that the latter, despite showing human-level accuracy\\nin such a task, probably solve it in ways radically different, but no less\\nrelevant to intelligence research, to those hypothesised for humans.\", 'authors': ['Dimitri Coelho Mollo'], 'published': datetime.datetime(2024, 1, 15, 21, 6, 20, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2401.07964v3'}, {'title': 'Artificial Intelligence Supported Shell-Model Calculations for Light Sn Isotopes', 'summary': 'The region around the doubly magic nuclide $^{100}Sn$ is very interesting for\\nnuclear physics studies in terms of structure, reaction and nuclear\\nastrophysics. The main ingredients in nuclear structure studies using the shell\\nmodel are the single-particle energies and the two-body matrix elements. To\\nobtain the former, experimental data of $^{101}Sn$ isotope spectrum are\\nnecessary. Since there is not enough experimental data, different approaches\\nare used in the literature to obtain single-particle energies. In sn100pn\\ninteraction, the hole excitation spectrum was used in $^{131}Sn$ to determine\\nneutron single-particle energies. The other approach is the use of the lightest\\nisotope, $^{107}Sn$, which figures the model space orbitals. In this study, we\\nestimated the spectrum of the $^{101}Sn$ isotope by artificial neural network\\nmethod in order to obtain neutron single-particle energies. After the training\\nwas carried out by using the experimental spectra of the nuclei around\\n$^{100}Sn$ isotope, the $^{101}Sn$ spectrum was obtained. Subsequently, neutron\\nSPEs of the model space orbitals are defined. Shell model calculations for\\n$^{102-108}Sn$ isotopes are carried out and results are compared to the\\nexperimental data and results obtained using the widely used interaction in the\\nregion, sn100pn. According to the results, it is seen that the Sn isotope\\nspectra obtained with the new SPE values are more compatible with the\\nexperimental data.', 'authors': ['Serkan Akkoyun', 'Abderrahmane Yakhelef'], 'published': datetime.datetime(2021, 11, 9, 6, 25, 6, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2112.12562v1'}, {'title': 'Intelligence Sequencing and the Path-Dependence of Intelligence Evolution: AGI-First vs. DCI-First as Irreversible Attractors', 'summary': 'The trajectory of intelligence evolution is often framed around the emergence\\nof artificial general intelligence (AGI) and its alignment with human values.\\nThis paper challenges that framing by introducing the concept of intelligence\\nsequencing: the idea that the order in which AGI and decentralized collective\\nintelligence (DCI) emerge determines the long-term attractor basin of\\nintelligence. Using insights from dynamical systems, evolutionary game theory,\\nand network models, it argues that intelligence follows a path-dependent,\\nirreversible trajectory. Once development enters a centralized (AGI-first) or\\ndecentralized (DCI-first) regime, transitions become structurally infeasible\\ndue to feedback loops and resource lock-in. Intelligence attractors are modeled\\nin functional state space as the co-navigation of conceptual and adaptive\\nfitness spaces. Early-phase structuring constrains later dynamics, much like\\nrenormalization in physics. This has major implications for AI safety:\\ntraditional alignment assumes AGI will emerge and must be controlled after the\\nfact, but this paper argues that intelligence sequencing is more foundational.\\nIf AGI-first architectures dominate before DCI reaches critical mass,\\nhierarchical monopolization and existential risk become locked in. If DCI-first\\nemerges, intelligence stabilizes around decentralized cooperative equilibrium.\\nThe paper further explores whether intelligence structurally biases itself\\ntoward an attractor based on its self-modeling method -- externally imposed\\naxioms (favoring AGI) vs. recursive internal visualization (favoring DCI).\\nFinally, it proposes methods to test this theory via simulations, historical\\nlock-in case studies, and intelligence network analysis. The findings suggest\\nthat intelligence sequencing is a civilizational tipping point: determining\\nwhether the future is shaped by unbounded competition or unbounded cooperation.', 'authors': ['Andy E. Williams'], 'published': datetime.datetime(2025, 3, 22, 8, 9, 4, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2503.17688v1'}, {'title': 'Change Guiding Network: Incorporating Change Prior to Guide Change Detection in Remote Sensing Imagery', 'summary': \"The rapid advancement of automated artificial intelligence algorithms and\\nremote sensing instruments has benefited change detection (CD) tasks. However,\\nthere is still a lot of space to study for precise detection, especially the\\nedge integrity and internal holes phenomenon of change features. In order to\\nsolve these problems, we design the Change Guiding Network (CGNet), to tackle\\nthe insufficient expression problem of change features in the conventional\\nU-Net structure adopted in previous methods, which causes inaccurate edge\\ndetection and internal holes. Change maps from deep features with rich semantic\\ninformation are generated and used as prior information to guide multi-scale\\nfeature fusion, which can improve the expression ability of change features.\\nMeanwhile, we propose a self-attention module named Change Guide Module (CGM),\\nwhich can effectively capture the long-distance dependency among pixels and\\neffectively overcome the problem of the insufficient receptive field of\\ntraditional convolutional neural networks. On four major CD datasets, we verify\\nthe usefulness and efficiency of the CGNet, and a large number of experiments\\nand ablation studies demonstrate the effectiveness of CGNet. We're going to\\nopen-source our code at https://github.com/ChengxiHAN/CGNet-CD.\", 'authors': ['Chengxi Han', 'Chen Wu', 'Haonan Guo', 'Meiqi Hu', 'Jiepan Li', 'Hongruixuan Chen'], 'published': datetime.datetime(2024, 4, 14, 8, 9, 33, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2404.09179v1'}, {'title': 'Interpretable AI forecasting for numerical relativity waveforms of quasi-circular, spinning, non-precessing binary black hole mergers', 'summary': 'We present a deep-learning artificial intelligence model that is capable of\\nlearning and forecasting the late-inspiral, merger and ringdown of numerical\\nrelativity waveforms that describe quasi-circular, spinning, non-precessing\\nbinary black hole mergers. We used the NRHybSur3dq8 surrogate model to produce\\ntrain, validation and test sets of $\\\\ell=|m|=2$ waveforms that cover the\\nparameter space of binary black hole mergers with mass-ratios $q\\\\leq8$ and\\nindividual spins $|s^z_{\\\\{1,2\\\\}}| \\\\leq 0.8$. These waveforms cover the time\\nrange $t\\\\in[-5000\\\\textrm{M}, 130\\\\textrm{M}]$, where $t=0M$ marks the merger\\nevent, defined as the maximum value of the waveform amplitude. We harnessed the\\nThetaGPU supercomputer at the Argonne Leadership Computing Facility to train\\nour AI model using a training set of 1.5 million waveforms. We used 16 NVIDIA\\nDGX A100 nodes, each consisting of 8 NVIDIA A100 Tensor Core GPUs and 2 AMD\\nRome CPUs, to fully train our model within 3.5 hours. Our findings show that\\nartificial intelligence can accurately forecast the dynamical evolution of\\nnumerical relativity waveforms in the time range $t\\\\in[-100\\\\textrm{M},\\n130\\\\textrm{M}]$. Sampling a test set of 190,000 waveforms, we find that the\\naverage overlap between target and predicted waveforms is $\\\\gtrsim99\\\\%$ over\\nthe entire parameter space under consideration. We also combined scientific\\nvisualization and accelerated computing to identify what components of our\\nmodel take in knowledge from the early and late-time waveform evolution to\\naccurately forecast the latter part of numerical relativity waveforms. This\\nwork aims to accelerate the creation of scalable, computationally efficient and\\ninterpretable artificial intelligence models for gravitational wave\\nastrophysics.', 'authors': ['Asad Khan', 'E. A. Huerta', 'Huihuo Zheng'], 'published': datetime.datetime(2021, 10, 13, 18, 14, 52, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2110.06968v2'}, {'title': 'A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal Holes', 'summary': 'The detection and analysis of the solar coronal holes (CHs) is an important\\nfield of study in the domain of solar physics. Mainly, it is required for the\\nproper prediction of the geomagnetic storms which directly or indirectly affect\\nvarious space and ground-based systems. For the detection of CHs till date, the\\nsolar scientist depends on manual hand-drawn approaches. However, with the\\nadvancement of image processing technologies, some automated image segmentation\\nmethods have been used for the detection of CHs. In-spite of this, fast and\\naccurate detection of CHs are till a major issues. Here in this work, a novel\\nquantum computing-based fast fuzzy c-mean technique has been developed for fast\\ndetection of the CHs region. The task has been carried out in two stages, in\\nfirst stage the solar image has been segmented using a quantum computing based\\nfast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted\\nout from the segmented image based on image morphological operation. In the\\nwork, quantum computing has been used to optimize the cost function of the fast\\nfuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm\\n(QAOA) has been used to optimize the quadratic part of the cost function. The\\nproposed method has been tested for 193 \\\\AA{} SDO/AIA full-disk solar image\\ndatasets and has been compared with the existing techniques. The outcome shows\\nthe comparable performance of the proposed method with the existing one within\\na very lesser time.', 'authors': ['Sanmoy Bandyopadhyay', 'Suman Kundu'], 'published': datetime.datetime(2024, 3, 27, 8, 38, 56, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2403.18347v1'}, {'title': 'Crack Path Prediction with Operator Learning using Discrete Particle System data Generation', 'summary': 'Accurately modeling crack propagation is critical for predicting failure in\\nengineering materials and structures, where small cracks can rapidly evolve and\\ncause catastrophic damage. The interaction of cracks with discontinuities, such\\nas holes, significantly affects crack deflection and arrest. Recent\\ndevelopments in discrete particle systems with multibody interactions based on\\nconstitutive behavior have demonstrated the ability to capture crack nucleation\\nand evolution without relying on continuum assumptions. In this work, we use\\ndata from Constitutively Informed Particle Dynamics (CPD) simulations to train\\noperator learning models, specifically Deep Operator Networks (DeepONets),\\nwhich learn mappings between function spaces instead of finite-dimensional\\nvectors. We explore two DeepONet variants: vanilla and Fusion DeepONet, for\\npredicting time-evolving crack propagation in specimens with varying\\ngeometries. Three representative cases are studied: (i) varying notch height\\nwithout active fracture; and (ii) and (iii) combinations of notch height and\\nhole radius where dynamic fracture occurs on irregular discrete meshes. The\\nmodels are trained on 32 to 45 samples, using geometric inputs in the branch\\nnetwork and spatial-temporal coordinates in the trunk network. Results show\\nthat Fusion DeepONet consistently outperforms the vanilla variant, with more\\naccurate predictions especially in non-fracturing cases. Fracture-driven\\nscenarios involving displacement and crack evolution remain more challenging.\\nThese findings highlight the potential of Fusion DeepONet to generalize across\\ncomplex, geometry-varying, and time-dependent crack propagation phenomena.', 'authors': ['Elham Kiyani', 'Venkatesh Ananchaperumal', 'Ahmad Peyvan', 'Mahendaran Uchimali', 'Gang Li', 'George Em Karniadakis'], 'published': datetime.datetime(2025, 5, 15, 23, 25, 21, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2506.01976v1'}, {'title': 'Construction and application of artificial intelligence crowdsourcing map based on multi-track GPS data', 'summary': 'In recent years, the rapid development of high-precision map technology\\ncombined with artificial intelligence has ushered in a new development\\nopportunity in the field of intelligent vehicles. High-precision map technology\\nis an important guarantee for intelligent vehicles to achieve autonomous\\ndriving. However, due to the lack of research on high-precision map technology,\\nit is difficult to rationally use this technology in the field of intelligent\\nvehicles. Therefore, relevant researchers studied a fast and effective\\nalgorithm to generate high-precision GPS data from a large number of\\nlow-precision GPS trajectory data fusion, and generated several key data points\\nto simplify the description of GPS trajectory, and realized the \"crowdsourced\\nupdate\" model based on a large number of social vehicles for map data\\ncollection came into being. This kind of algorithm has the important\\nsignificance to improve the data accuracy, reduce the measurement cost and\\nreduce the data storage space. On this basis, this paper analyzes the\\nimplementation form of crowdsourcing map, so as to improve the various\\ninformation data in the high-precision map according to the actual situation,\\nand promote the high-precision map can be reasonably applied to the intelligent\\ncar.', 'authors': ['Yong Wang', 'Yanlin Zhou', 'Huan Ji', 'Zheng He', 'Xinyu Shen'], 'published': datetime.datetime(2024, 2, 24, 11, 54, 32, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2402.15796v1'}, {'title': 'Rapid search for massive black hole binary coalescences using deep learning', 'summary': 'The coalescences of massive black hole binaries are one of the main targets\\nof space-based gravitational wave observatories. Such gravitational wave\\nsources are expected to be accompanied by electromagnetic emissions. Low\\nlatency detection of the massive black hole mergers provides a start point for\\na global-fit analysis to explore the large parameter space of signals\\nsimultaneously being present in the data but at great computational cost. To\\nalleviate this issue, we present a deep learning method for rapidly searching\\nfor signals of massive black hole binaries in gravitational wave data. Our\\nmodel is capable of processing a year of data, simulated from the LISA data\\nchallenge, in only several seconds, while identifying all coalescences of\\nmassive black hole binaries with no false alarms. We further demonstrate that\\nthe model shows robust resistance to a wide range of generalization cases,\\nincluding various waveform families and updated instrumental configurations.\\nThis method offers an effective approach that combines advances in artificial\\nintelligence to open a new pathway for space-based gravitational wave\\nobservations.', 'authors': ['Wen-Hong Ruan', 'He Wang', 'Chang Liu', 'Zong-Kuan Guo'], 'published': datetime.datetime(2021, 11, 29, 14, 18, 17, tzinfo=datetime.timezone.utc), 'arxiv_id': 'http://arxiv.org/abs/2111.14546v2'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"downloaded articles:\", download_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22d655b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: archive/2110.03318v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 15750 characters\n",
      "Processing: archive/2405.09802v3.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 15757 characters\n",
      "Processing: archive/2111.11295v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 25829 characters\n",
      "Processing: archive/1105.2015v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 2471 characters\n",
      "Processing: archive/2405.01134v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 41162 characters\n",
      "Processing: archive/2402.18002v2.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 29471 characters\n",
      "Processing: archive/2005.10488v1.pdf\n",
      "Found Abstract section\n",
      "No bibliography found, using full text from start position\n",
      "Extracted 21076 characters\n",
      "Processing: archive/2412.02671v2.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 2553 characters\n",
      "Processing: archive/1906.03997v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 26722 characters\n",
      "Processing: archive/1509.01213v1.pdf\n",
      "Found Abstract section\n",
      "No bibliography found, using full text from start position\n",
      "Extracted 8617 characters\n",
      "Processing: archive/2312.01836v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 33169 characters\n",
      "Processing: archive/2401.07964v3.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 64247 characters\n",
      "Processing: archive/2112.12562v1.pdf\n",
      "Abstract not found, starting from: INTRODUCTION\n",
      "No bibliography found, using full text from start position\n",
      "Extracted 42193 characters\n",
      "Processing: archive/2503.17688v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 5876 characters\n",
      "Processing: archive/2404.09179v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 50044 characters\n",
      "Processing: archive/2110.06968v2.pdf\n",
      "Found Abstract section\n",
      "No bibliography found, using full text from start position\n",
      "Extracted 40732 characters\n",
      "Processing: archive/2403.18347v1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray stroke color because /'P8' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P8' is an invalid float value\n",
      "Cannot set gray stroke color because /'P10' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P10' is an invalid float value\n",
      "Cannot set gray stroke color because /'P12' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P12' is an invalid float value\n",
      "Cannot set gray stroke color because /'P13' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P13' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 37556 characters\n",
      "Processing: archive/2506.01976v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 48991 characters\n",
      "Processing: archive/2402.15796v1.pdf\n",
      "Found Abstract section\n",
      "Found bibliography section, text truncated\n",
      "Extracted 19786 characters\n",
      "Processing: archive/2111.14546v2.pdf\n",
      "Abstract not found, starting from: INTRODUCTION\n",
      "No bibliography found, using full text from start position\n",
      "Extracted 41915 characters\n"
     ]
    }
   ],
   "source": [
    "articles = PDFToText(pdf_path='archive').convert_to_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe18f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaromek/Programming/Repos/researchAgent/embedding/embeddingArticle.py:21: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(\n",
      "No sentence-transformers model found with name allenai/scibert_scivocab_uncased. Creating a new one with mean pooling.\n",
      "/home/jaromek/Programming/Repos/researchAgent/embedding/embeddingArticle.py:40: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
      "  self.vectorstore = Qdrant(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to embed 20 articles...\n",
      "Processing article 1/20...\n",
      "  - Created 52 chunks\n",
      "  - Added 52 chunks to vectorstore\n",
      "Processing article 2/20...\n",
      "  - Created 47 chunks\n",
      "  - Added 47 chunks to vectorstore\n",
      "Processing article 3/20...\n",
      "  - Created 73 chunks\n",
      "  - Added 73 chunks to vectorstore\n",
      "Processing article 4/20...\n",
      "  - Created 8 chunks\n",
      "  - Added 8 chunks to vectorstore\n",
      "Processing article 5/20...\n",
      "  - Created 125 chunks\n",
      "  - Added 125 chunks to vectorstore\n",
      "Processing article 6/20...\n",
      "  - Created 94 chunks\n",
      "  - Added 94 chunks to vectorstore\n",
      "Processing article 7/20...\n",
      "  - Created 61 chunks\n",
      "  - Added 61 chunks to vectorstore\n",
      "Processing article 8/20...\n",
      "  - Created 9 chunks\n",
      "  - Added 9 chunks to vectorstore\n",
      "Processing article 9/20...\n",
      "  - Created 84 chunks\n",
      "  - Added 84 chunks to vectorstore\n",
      "Processing article 10/20...\n",
      "  - Created 29 chunks\n",
      "  - Added 29 chunks to vectorstore\n",
      "Processing article 11/20...\n",
      "  - Created 97 chunks\n",
      "  - Added 97 chunks to vectorstore\n",
      "Processing article 12/20...\n",
      "  - Created 176 chunks\n",
      "  - Added 176 chunks to vectorstore\n",
      "Processing article 13/20...\n",
      "  - Created 130 chunks\n",
      "  - Added 130 chunks to vectorstore\n",
      "Processing article 14/20...\n",
      "  - Created 19 chunks\n",
      "  - Added 19 chunks to vectorstore\n",
      "Processing article 15/20...\n",
      "  - Created 125 chunks\n",
      "  - Added 125 chunks to vectorstore\n",
      "Processing article 16/20...\n",
      "  - Created 116 chunks\n",
      "  - Added 116 chunks to vectorstore\n",
      "Processing article 17/20...\n",
      "  - Created 111 chunks\n",
      "  - Added 111 chunks to vectorstore\n",
      "Processing article 18/20...\n",
      "  - Created 141 chunks\n",
      "  - Added 141 chunks to vectorstore\n",
      "Processing article 19/20...\n",
      "  - Created 59 chunks\n",
      "  - Added 59 chunks to vectorstore\n",
      "Processing article 20/20...\n",
      "  - Created 127 chunks\n",
      "  - Added 127 chunks to vectorstore\n",
      "Finished embedding all articles!\n"
     ]
    }
   ],
   "source": [
    "EmbeddingArticle(articles=articles).embed_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e400af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIDev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
